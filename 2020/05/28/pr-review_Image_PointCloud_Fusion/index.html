<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/bitbug_favicon32x32.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/bitbug_favicon16x16.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://zhxjia.github.io').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.7.1',
    exturl: false,
    sidebar: {"position":"right","display":"always","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":true,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: true,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: 'JFFLKNTBOH',
      apiKey: '12c519466e9111e97c1a9fa4f29a7156',
      indexName: 'zhxjia',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="​ 相机与Lidar点云融合的综述文章。针对点云和图像数据结构特征的差异，提出了目前这两种传感器融合方面的切入点和发展趋势。无人驾驶要求对周围3D环境进行可靠的感知，单目相机原理上不能提供3D几何信息，而双目相机虽然可以提供3D几何信息，但其引入计算量同时探测距离有限对环境条件要求较高，因此在无人驾驶环境下使用的较少。Lidar能够提供高精度的几何信息同时不受光线条件的影响，但是存在采样稀疏，语义">
<meta property="og:type" content="article">
<meta property="og:title" content="《Deep Learning for Image and Point Clound Fusion in Autonomous Driving:A Review》">
<meta property="og:url" content="https://zhxjia.github.io/2020/05/28/pr-review_Image_PointCloud_Fusion/index.html">
<meta property="og:site_name" content="ZhxJia&#39;s Blog">
<meta property="og:description" content="​ 相机与Lidar点云融合的综述文章。针对点云和图像数据结构特征的差异，提出了目前这两种传感器融合方面的切入点和发展趋势。无人驾驶要求对周围3D环境进行可靠的感知，单目相机原理上不能提供3D几何信息，而双目相机虽然可以提供3D几何信息，但其引入计算量同时探测距离有限对环境条件要求较高，因此在无人驾驶环境下使用的较少。Lidar能够提供高精度的几何信息同时不受光线条件的影响，但是存在采样稀疏，语义">
<meta property="og:image" content="https://zhxjia.github.io/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200521161943634.png">
<meta property="og:image" content="https://zhxjia.github.io/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200521161607067.png">
<meta property="og:image" content="https://zhxjia.github.io/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200524204555123.png">
<meta property="og:image" content="https://zhxjia.github.io/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200526193634386.png">
<meta property="og:image" content="https://zhxjia.github.io/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200527211057103.png">
<meta property="og:image" content="https://zhxjia.github.io/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200527220324567.png">
<meta property="og:image" content="https://zhxjia.github.io/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200527223109666.png">
<meta property="article:published_time" content="2020-05-28T01:42:25.090Z">
<meta property="article:modified_time" content="2020-05-28T01:42:25.090Z">
<meta property="article:author" content="ZhxJia">
<meta property="article:tag" content="传感器融合">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhxjia.github.io/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200521161943634.png">

<link rel="canonical" href="https://zhxjia.github.io/2020/05/28/pr-review_Image_PointCloud_Fusion/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>《Deep Learning for Image and Point Clound Fusion in Autonomous Driving:A Review》 | ZhxJia's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ZhxJia's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">半路出家</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input" id="search-input"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

  
</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://zhxjia.github.io/2020/05/28/pr-review_Image_PointCloud_Fusion/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/jd.png">
      <meta itemprop="name" content="ZhxJia">
      <meta itemprop="description" content="行则将至">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZhxJia's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          《Deep Learning for Image and Point Clound Fusion in Autonomous Driving:A Review》
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-28 09:42:25" itemprop="dateCreated datePublished" datetime="2020-05-28T09:42:25+08:00">2020-05-28</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index">
                    <span itemprop="name">论文阅读</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/2020/05/28/pr-review_Image_PointCloud_Fusion/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/05/28/pr-review_Image_PointCloud_Fusion/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>8.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>14 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>​ 相机与Lidar点云融合的综述文章。针对点云和图像数据结构特征的差异，提出了目前这两种传感器融合方面的切入点和发展趋势。无人驾驶要求对周围3D环境进行可靠的感知，单目相机原理上不能提供3D几何信息，而双目相机虽然可以提供3D几何信息，但其引入计算量同时探测距离有限对环境条件要求较高，因此在无人驾驶环境下使用的较少。Lidar能够提供高精度的几何信息同时不受光线条件的影响，但是存在采样稀疏，语义信息匮乏的问题。 ​ 为了应对无人驾驶感知任务的挑战，当前许多研究致力于如何有效的融合这两种互补的传感器信息。</p>
<p><img src="/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200521161943634.png" alt="image-20200521161943634" style="zoom: 33%;"></p>
<a id="more"></a>
<p>深度学习方法在图像中的应用：图像中编码的是可见光信息，目前基于CNN的相关网络结构得到的广泛的研究。 由于点云数据结构(无序，不规则,密度不均衡(近多远少))的特点，直接应用已有的网络结构比较困难，目前针对点云数据的处理方式有：</p>
<ol type="1">
<li>Volumetric representation based(基于体素网格的方法)：将点云划分到3D网格中，从而可以直接应用3D convolution 这种划分方法存在问题：高分辨率的3D体素网格(voxel-space)大幅增加了计算量，同时点云的稀疏性导致了大量的空网格且会随着分辨率的提升立方增长。 [参考:Voxelnet][https://arxiv.org/pdf/1711.06396.pdf] [参考:Voxnet][https://ieeexplore.ieee.org/document/7353481]</li>
<li>Tree-like representation based(基于树状结构的方法)：出发点为了减轻高分辨率带来的高计算量的约束，通过将点云划分到一系列的不平衡树（八叉树），使得低密度的点只有较低的分辨率，减少不必要的空间和计算资源浪费。特征提取采用类卷积的操作。 [参考:Octnet][https://arxiv.org/abs/1611.05009] [参考:context-based octree][https://ieeexplore.ieee.org/document/8784388] [参考:octree guided cnn][https://arxiv.org/abs/1903.00343] [参考:3dcontextnet][https://arxiv.org/abs/1711.11379]</li>
<li>Point representation based: (基于原始点云的表示方法)：该方法采用原始点云，开创工作是[pointNet][https://arxiv.org/abs/1706.02413]</li>
<li>2D view representation based(基于点云投影2D视图的表示方法)：这种方法将点云投影到某个2D平面,2D平面中每个点编码了点云的特征(类似于图像的特征图)，常用的2D投影平面例如鸟瞰图(bird's-eye view,BEW),这种投影方式视角遮挡最小，同时原始的物体朝向和x,y坐标被保留。目前常用的特征表述包括了(average points height,density and intesity)。标准的2D卷积和现有的卷积框架结构可以被直接使用。</li>
<li>Geometric representation based(基于几何的表示方法)：点云可以表示为图(拓扑)结构，类卷积操作可以实现用于特征提取。 [参考:graph topology inference][https://arxiv.org/abs/1905.04571] [参考:deep cnn for graph data][https://arxiv.org/abs/1506.05163] [参考:edge-conditioned filters][https://arxiv.org/abs/1704.02901]</li>
</ol>
<p>点云的特征表示方式目前还是一个开放的问题。</p>
<h2 id="论文总体结构">1. 论文总体结构</h2>
<p>论文从四个方面(Depth completion , object detection, semantic segmentation, object tracking)概述了图像和点云融合的相关进展。</p>
<figure>
<img src="/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200521161607067.png" alt="image-20200521161607067"><figcaption>image-20200521161607067</figcaption>
</figure>
<h2 id="无人驾驶感知的挑战">2. 无人驾驶感知的挑战</h2>
<h3 id="depth-completion">2.1 Depth Completion</h3>
<p>深度补全是指通过上采样稀疏不规则的数据到密集规则的数据。Camera-Lidar融合的方法通常利用高分辨率的图像指导上采样，实现pixel-wise层级上的深度图。下图按照时间顺序给出了深度补全模型和对应的融合层级。</p>
<figure>
<img src="/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200524204555123.png" alt="image-20200524204555123"><figcaption>image-20200524204555123</figcaption>
</figure>
<h3 id="d-object-detection">2.2 3D object detection</h3>
<p>​ 3D目标检测方法的目的是在3D空间中定位，分类以及估计障碍物的朝向。目前有两种主流的实现方法： ​ two-step(Sequential)和one-step。two-step(Sequential)包含了两个阶段：proposal和regression。one-step直接并行输出2D和3D信息。</p>
<p>下图按照时间顺序展示了3D目标检测的相关工作，并标注了相机和lidar对应的融合层级。</p>
<figure>
<img src="/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200526193634386.png" alt="image-20200526193634386"><figcaption>image-20200526193634386</figcaption>
</figure>
<ol type="1">
<li>2D proposal based sequential models 试图利用2D图像语义信息提供3D proposal的初始区域：利用现有的图像处理框架生成2D region proposal，然后投影到3D空间，2D-&gt;3D的投影过程有两种主要方法，其中之一是将图像平面边界框投影到3D点云空间，结果形成了一个视锥型搜索空间，第二种方法是将点云投影到图像平面，结果是使点云具有2D语义信息。 下面按照融合层级给出这方面的相关工作：
<ol type="1">
<li>Result-level Fusion:信息融合发生在最后result阶段 这种方法的直接直觉来源是利用现有的2D目标检测方法缩小3D目标检测的搜索区域。最直接的方法就是将2D bbox反投影到3D空间，这样将多个感兴趣的小区域替代整个点云的处理以减少计算量，然而这种方法由于采用了2D bbox的检测结果因此整体性能会受限于2D detector的性能。Result-level Fusion核心思想是不利用多模态的数据进行互补，只是用于减少计算量。 早期的工作有 [F-PointNet][https://arxiv.org/abs/1711.08488]将图像生成的2d bbox反投影得到的视锥体区域点云送入PointNet中。[A general pipeline for 3d detection of vehicles][https://arxiv.org/abs/1803.00387]这篇论文中在2D到3D proposal生成阶段加入了额外的基于模型拟合方法的细化操作，将感兴趣区域内的背景点去除，将过滤后的点送入bbox回归网络中。[RoarNet][https://arxiv.org/abs/1811.03818]将细化操作用神经网络代替。 这些方法存在的问题是：假设得到的seed region仅包含一个目标，这对于拥挤场景和小目标(如行人)是不合理的。 该问题的解决方法有将2D目标检测器替换为2D语义分割网络,这样region-wise级别的提议改为point-wise级别的提议。[Intensive Point-based Object Detector :IPod][https://arxiv.org/abs/1812.05276] 在这个方向上做了相关工作，首先将点云投影到图像中利用2D语义分割信息过滤背景点。</li>
</ol>
<p>(2)Multi-level Fusion:结合result-level和feature-level。 典型的工作有[PointFusion][https://arxiv.org/abs/1711.10871],利用现有2D目标检测器生成2Dbbox，通过将点云投影到图像平面中选择对应在bbox中的点，最终分别通过Resnet和Pointnet基础架构在每一个proposal上融合图像和点云特征 预测3D目标，然而在proposal阶段仅仅利用了图像这一个模态。[SIFRNet][https://arxiv.org/abs/1901.02237]中frustum proposal首先从图像中生成，在frustum proposal中的点云特征与对应的图像特征融合用于最终3d bbox的回归。IPod</p>
<p>(3)feature-level Fusion:多模态融合 多模态融合的早期尝试是在像素层级pixel-wise上进行的，将3D几何特征通过某些方式(例如鸟瞰图)转换为2D图像格式，然后附加到图像通道上，基本理想是将3D几何特征投影到图像平面上然后利用现有的图像处理框架直接处理，这种方法的输出也是在限制于图像平面中，不是3D空间物体检测的理想方式。[DepthRCNN][https://arxiv.org/abs/1407.5736]编码3D几何信息(HHA，来自RGBD)到相机RGB通道中。[Fusing lidar and images for pedestrian detection using convolutional neural networks][https://ieeexplore.ieee.org/document/7487370] 这篇论文中进行了扩展，3D几何信息(HHA)由lidar产生。 为了在3D空间中更准的定位物体，目前常用point-wise层级上的融合，通过这种方式图像与点云中的点一一关联。[PointPainting][https://arxiv.org/abs/1911.10150]将点云投影到2D语义分割图中(利用之前提到过的Ipod)，然而除了利用2D语义过滤点云，2D语义仅简单地附加到点云中作为额外的通道。</p></li>
<li><p>3D proposal based sequential model</p>
<p>​ 相较于2D proposal,该方法直接从2D/3D数据生成3D Proposal。消除2D到3D转换的阶段大大缩小了目标检测的3D搜索空间。通用的生成3D proposal的方法有多视角(multi-view)或者点云体素化(voxelization)</p>
<ul>
<li>多视角方法(multi-view)利用点云的鸟瞰图(bird'eye view,BEV)进行3D proposal生成。鸟瞰图保留物体的旋转方向和x,y坐标信息。</li>
<li>点云体素化(voxelization)将原先连续的不规则的数据结构转换为离散的规则的数据结构，这样可以直接利用3D CNN,缺点是损失了空间分辨率。</li>
</ul>
<p>​ (1) Feature-level fusion: ​ 从BEV表示生成3D Proposal的重要工作是[MV3D][https://arxiv.org/abs/1611.07759],利用lidar特征图(包括height,density,intensity)生成3D候选区域，然后将他们投影到前视图(front view)与图像数据融合进行边界框回归。融合发生在Roi pooling阶段，因此是ROI-level层级的融合，这项工作中存在的问题有通过BEV生成3D proposal过程中假设所有的目标都被捕获，针对小目标物体(行人，骑自行车的人)的识别可能表现并不是很好，因为可能被其他大的目标遮挡。其次，小目标在连续的卷积下采样过程中可能丢失。同时，在roipooling过程中进行融合可能会损失细粒度信息。 ​ 为了提升对小目标的检测能力，[Aggregate View Object Detection network (AVOD)][https://arxiv.org/abs/1712.02294]通过同时利用BEV和图像特征提升MV3D中的proposal阶段。图像分支利用auto-encoder结构上采样最终特征图到它原始大小。[Scanet][http://150.162.46.34:8080/icassp2019/ICASSP2019/pdfs/0001992.pdf]中也实现了encoder-decoder并利用了Spatial-Channel Attention(SCA)和Extension Spatial Unsample(ESU)模块。</p>
<p>​ 上述方法以object为中心在ROI-pooling阶段(roi-wise fusion)进行融合损失了细粒度的几何信息。[ContFuse][http://openaccess.thecvf.com/content_ECCV_2018/papers/Ming_Liang_Deep_Continuous_Fusion_ECCV_2018_paper.pdf]通过在point-wise进行融合应对这个问题，这种point-wise融合通过[continuous convolutions][http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Deep_Parametric_Continuous_CVPR_2018_paper.pdf] 实现。首先提取BEV视图中每一个像素的K个最近邻点，然后将这些点映射到图像平面中以检索对应的图像特征，最终融合的特征向量根据与期望像素的几何偏移加权送入MLP中。 然而这种融合方法由于点云的稀疏性可能不能充分融合高分辨率图像的特征。[Multi-task multisensor fusion for 3d object detection][http://www.cs.toronto.edu/~byang/papers/mmf.pdf]中综合了多个层级的融合策略(signal-level,feature-level,multi-view,depth completion)。上述基于point-wise/pixel-wise层级融合会产生特征模糊(feature blurring)的问题,即可能存在点云中的点对应多个图像中的像素或者反之，这会混淆数据融合。</p>
<p>​ 直接将RGB图像信息附加作为voxel的额外通道是最简单的组合体素点云和图像的方法，这种方法存在的问题是体素化表示破坏了细粒度局部几何信息，同时由于图像和点云分辨率不一致是的融合过程效率较低。</p></li>
<li><p>One-step Models 一步模型将proposal generation和bbox回归的过程合为一步。[MVX-Net][https://arxiv.org/abs/1904.01649]介绍了两种方法用于在point-wise和voxel-wise层级融合图像和点云，采用预训练的2D CNN用于图像特征提取，同时采用[VoxelNet][https://arxiv.org/abs/1711.06396]作为框架从融合的点云中预测物体。在point-wise融合方法中，点云首先被映射到图像特征空间用于在VoxelNet网络处理前提取图像特征。在Voxel-wise融合方法中，在将非空的voxel映射到图像特征空间之前首先体素化点云。 [Lasernet][https://arxiv.org/abs/1903.08701]是一个多任务和多模态网络，用于融合点云和图像的3D目标检测和3D语义分割。两个CNN并行处理lidar产生的深度图像和前视图并且通过将点投影到图像平面关联对应的图像特征。特征图送入LaserNet中预测每一个点bbox的分布并生成最终的3D proposal。</p></li>
</ol>
<h3 id="d3d-semantic-segmentation">2.3 2D/3D semantic segmentation</h3>
<p>回顾camera-lidar融合的2D/3D语义分割，实例分割方法，下图按时间顺序给出3D语义分割网络和对应的融合等级。 <img src="/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200527211057103.png" alt="image-20200527211057103" style="zoom:67%;"></p>
<ol type="1">
<li>2D Semantic Segmentation
<ol type="1">
<li>Feature-level Fusion: [Self-supervised model adaptation for multimodal semantic segmentation][https://arxiv.org/abs/1808.03833]采用不同深度多阶段特征融合进行语义分割。[Lidarcamera fusion for road detection using fully convolutional neural networks][https://arxiv.org/abs/1809.07941]论文中通过利用上采样的深度图和图像来进行语义分割，通过上采样来自点云的稀疏深度图同时利用相机图像获得密集的深度图。</li>
</ol></li>
<li>3D Semantic Segmentation
<ol type="1">
<li>Feature-level Fusion:</li>
</ol>
<p>​ [3DMV][https://arxiv.org/abs/1803.10409]是融合图像语义和点云(RGBD)特征的多视角网络，来自多个视角的图像特对齐后通过2D卷积网络提取特征并映射到3D空间。这种基于体素的方法性能受限于体素的分辨率。针对该问题，[UPF][https://arxiv.org/abs/1908.00478]是基于点的3D语义分割框架，基于根本方法是[PointNet++][https://arxiv.org/abs/1706.02413]</p></li>
<li><p>Instance Segmentation</p>
<p>略</p></li>
</ol>
<blockquote>
<p>上述各种方法，目前在自动驾驶的实际场景中应用较少，没有细看，如果以后用到，可直接参考论文</p>
</blockquote>
<pre><code>### 2.4 3D Object Tracking</code></pre>
<p>多目标跟踪是自动驾驶感知不可缺少的环节，针对camera-lidar融合的目标跟踪方法总结如下，性能评价指标参考[KITTI][http://www.cvlibs.net/publications/Geiger2012CVPR.pdf]</p>
<figure>
<img src="/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200527220324567.png" alt="image-20200527220324567"><figcaption>image-20200527220324567</figcaption>
</figure>
<ol type="1">
<li><p>Detection-Based Tracking(DBT)基于检测器的目标跟踪方法</p>
<p>DBT(Tracking-by-Detection)跟踪框架包含两个阶段：第一步通过检测器检测目标，第二步进行数据关联，将同一目标按照时间轴构成一条跟踪轨迹。[End-to-end learning of multi-sensor 3d tracking by detection][https://arxiv.org/abs/1806.11534]提出了端到端的DBT训练框架，为了实现端到端的学习，检测和匹配通过一个深度结构化模块(DSM)实现。 貌似都是离线跟踪的方法，目前暂时用不到，详细看论文。</p></li>
<li><p>Detection-Free Tracking(DFT) [Complexer-YOLO][https://arxiv.org/abs/1904.07537]是一个解耦3D目标检测和跟踪的框架。</p></li>
</ol>
<h2 id="未来研究方向">3. 未来研究方向</h2>
<p>感知模块是无人驾驶中下游决策，规划，控制的前提，它的性能和可靠性是整个无人驾驶系统性能优劣的首要因素。因此，利用相机和lidar融合以更好的理解复杂环境。下表给出了提升camera-lidar融合算法的性能，可靠性以及相关工程实践的一些挑战。</p>
<figure>
<img src="/2020/05/28/pr-review_Image_PointCloud_Fusion/image-20200527223109666.png" alt="image-20200527223109666"><figcaption>image-20200527223109666</figcaption>
</figure>
<p>融合的发展趋势有：</p>
<ul>
<li><p>2D to 3D:</p></li>
<li><p>sing-task ot multi-tasks:考虑到移动平台的计算性能和实时性需求，网络往往需要多任务输出。</p></li>
<li><p>singal-level to multi-level Fusion:早期的工作集中于输入信号层级的融合，例如将点云投影到图像平面等，最近很多模型视图融合在多个层级上。</p></li>
</ul>
<p>深度估计：单目深度估计，融合深度估计</p>
<p>故障检测：相机在不利环境下(例如重影，光线不足，)</p>
<p>[自动驾驶相机-激光雷达深度融合综述及展望][https://mp.weixin.qq.com/s?__biz=MzI1ODYwOTkzNg==&amp;mid=2247500603&amp;idx=1&amp;sn=c8df20167dffe5ba6c4e850555293ad4&amp;chksm=ea070544dd708c5270a1380f95ff52386204a96d1c2b026697ded4e7f9089d6fc114ff62a026&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1586875366394&amp;sharer_shareid=251c7f638257dafd65dd3f515ad533cb&amp;key=0b6318e4d66e8464fd862767da5f8c51c286edb23c13d2df9762e0649316e1f8d9a5a96d352ad1c430a4868e0b78a343a61c26068054087211927f5b411c6fb5db9b716f1c218582b7d9d8347625c14b&amp;ascene=1&amp;uin=MjU0MTcyMzYzNw%3D%3D&amp;devicetype=Windows+10+x64&amp;version=62090070&amp;lang=zh_CN&amp;exportkey=A9Nk8Y3UMCPDtCIcH%2B6a0Lg%3D&amp;pass_ticket=M9LuIPgA%2BNn%2FM1hrwO9oOAOPG2geFBvwMZ15XwJ5RivYEn75h8Qufft2SOni6CDL]</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88/" rel="tag"># 传感器融合</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/05/13/apollo-lidar_tracker/" rel="prev" title="apollo lidar算法--recognition component（一）">
      <i class="fa fa-chevron-left"></i> apollo lidar算法--recognition component（一）
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#论文总体结构"><span class="nav-number">1.</span> <span class="nav-text">1. 论文总体结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#无人驾驶感知的挑战"><span class="nav-number">2.</span> <span class="nav-text">2. 无人驾驶感知的挑战</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#depth-completion"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 Depth Completion</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#d-object-detection"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 3D object detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#d3d-semantic-segmentation"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 2D&#x2F;3D semantic segmentation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#未来研究方向"><span class="nav-number">3.</span> <span class="nav-text">3. 未来研究方向</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="ZhxJia"
      src="/images/jd.png">
  <p class="site-author-name" itemprop="name">ZhxJia</p>
  <div class="site-description" itemprop="description">行则将至</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">50</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/ZhxJia" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ZhxJia" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:jachin9707@gmail.com" title="E-Mail → mailto:jachin9707@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

      
        <script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
        <script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
        <div class="widget-wrap">
          <h3 class="widget-title">Tag Cloud</h3>
          <div id="myCanvasContainer" class="widget tagcloud">
              <canvas width="250" height="250" id="resCanvas" style="width=100%">
                 <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Apollo/" rel="tag">Apollo</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MOT/" rel="tag">MOT</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/STL/" rel="tag">STL</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/apollo/" rel="tag">apollo</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/build/" rel="tag">build</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/c/" rel="tag">c++</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/caffe/" rel="tag">caffe</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/detector/" rel="tag">detector</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lidar%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag">lidar目标检测</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/lidar%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/" rel="tag">lidar目标跟踪</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/perception/" rel="tag">perception</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/radar/" rel="tag">radar</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell/" rel="tag">shell</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/slam/" rel="tag">slam</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/track/" rel="tag">track</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BC%98%E5%8C%96/" rel="tag">优化</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A0%87%E5%AE%9A/" rel="tag">传感器标定</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88/" rel="tag">传感器融合</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%8D%95%E8%A7%86%E5%9B%BE%E8%A1%A1%E9%87%8F/" rel="tag">单视图衡量</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9D%90%E6%A0%87%E8%BD%AC%E6%8D%A2/" rel="tag">坐标转换</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E8%9E%8D%E5%90%88/" rel="tag">多传感器融合</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B7%A5%E5%85%B7/" rel="tag">工具</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%84%9F%E7%9F%A5/" rel="tag">感知</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6/" rel="tag">无人驾驶</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A0%87%E5%AE%9A/" rel="tag">标定</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/" rel="tag">概率论</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/" rel="tag">目标跟踪</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A7%86%E8%A7%89/" rel="tag">视觉</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9A%9C%E7%A2%8D%E7%89%A9%E6%A3%80%E6%B5%8B/" rel="tag">障碍物检测</a><span class="tag-list-count">1</span></li></ul>
        </canvas>
       </div>
     </div>
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ZhxJia</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">297k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">8:15</span>
</div>

<span id="sitetime"></span>
<script language=javascript>
  function siteTime(){
    window.setTimeout("siteTime()", 1000);
    var seconds = 1000;
    var minutes = seconds * 60;
    var hours = minutes * 60;
    var days = hours * 24;
    var years = days * 365;
    var today = new Date();
    var todayYear = today.getFullYear();
    var todayMonth = today.getMonth()+1;
    var todayDate = today.getDate();
    var todayHour = today.getHours();
    var todayMinute = today.getMinutes();
    var todaySecond = today.getSeconds();
    /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
    year - 作为date对象的年份，为4位年份值
    month - 0-11之间的整数，做为date对象的月份
    day - 1-31之间的整数，做为date对象的天数
    hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
    minutes - 0-59之间的整数，做为date对象的分钟数
    seconds - 0-59之间的整数，做为date对象的秒数
    microseconds - 0-999之间的整数，做为date对象的毫秒数 */
    var t1 = Date.UTC(2020,01,28,00,00,00); //这里调整博客建站时间，时间：2019-05-14 00:00:00
    var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
    var diff = t2-t1;
    var diffYears = Math.floor(diff/years);
    var diffDays = Math.floor((diff/days)-diffYears*365);
    var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
    var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
    var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
    document.getElementById("sitetime").innerHTML=" 已运行"+/*diffYears+" 年 "+*/diffDays+" 天 "+diffHours+" 小时 "+diffMinutes+" 分钟 "+diffSeconds+" 秒";
  }/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
  siteTime();
</script>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.1
  </div>
  <div class="addthis_inline_share_toolbox">
    <script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e37e1f2e978cea8" async="async"></script>
  </div>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest-nomobile.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/instantsearch.js@2/dist/instantsearch.min.css">
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@2/dist/instantsearch.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  
      
<script type="text/x-mathjax-config">
    MathJax.Ajax.config.path['mhchem'] = '//cdn.jsdelivr.net/npm/mathjax-mhchem@3';

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        extensions: ['[mhchem]/mhchem.js'],
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://zhxjia.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://zhxjia.github.io/2020/05/28/pr-review_Image_PointCloud_Fusion/";
    this.page.identifier = "2020/05/28/pr-review_Image_PointCloud_Fusion/";
    this.page.title = "《Deep Learning for Image and Point Clound Fusion in Autonomous Driving:A Review》";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://zhxjia.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

  <script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":true,"debug":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
