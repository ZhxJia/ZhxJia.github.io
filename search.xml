<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>最优估计 -- kalman and lsm</title>
      <link href="/2020/02/03/kalman_filter_and_lsm/"/>
      <url>/2020/02/03/kalman_filter_and_lsm/</url>
      
        <content type="html"><![CDATA[<p>kalman Filter 和 least square 目的均为最优化某一指标，指标是优化的关键：</p><p>常用的估计准则有：</p><ul><li><p>无偏估计：估计值的期望等于被估计参数的真实值。</p></li><li><p>线性最小方差估计：将估计量限制为观测值的线性函数，已知观测量Z和和被估计量X一二阶矩（EX,Var{X},EZ,Var{Z},Cov{X,Z}）,使估计误差的方差最小，即最小化<span class="math inline">\(tr\{E[\tilde{X}-E\tilde{X}][\tilde{X}-E\tilde{X}]^{T}\}\)</span> ,<span class="math inline">\(\tilde{X}\)</span>为估计误差（等价于最小化均方误差阵，若为无偏估计）可得其无偏估计值为<span class="math inline">\(\tilde{X}_{LMV}(Z)=EX+cov(X,Z)(var(Z))^{-1}[Z-EZ]\)</span>对于观测模型Z=HX+V，上述条件若已知</p><p><span class="math inline">\(\{EX=\mu_x,Var(X)=P_x,EV=0,Var(V)=R,E(XV^T)=0\}\)</span> 即可得到。</p></li><li><p>最小二乘估计：对数据（X、Z）的统计特性一无所知，但仍需对X进行估计，目标是最小化残差<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>平方和。</p><p>满足最小方差必满足残差平方和最小，反之则不成立。</p></li></ul><a id="more"></a><h4 id="经典最小二乘">经典最小二乘</h4><p>针对隐状态X，若其无法直接观测，但间接获取其观测值<span class="math inline">\(Z=[z_1,z_2,\dots,z_n]^T\)</span> ,若其观测值为状态值的线性函数： <span class="math display">\[Z_i=H_iX+V_i,i=1,\dots,n\]</span> <span class="math inline">\(z_i\)</span>为第i次测量的观测值，<span class="math inline">\(H_i\)</span>为第i次测量的观测模型(设计矩阵，实验的观测值)，<span class="math inline">\(V_i\)</span>为第i次测量的噪声（误差）。</p><p>则第i次测量的估计误差： <span class="math display">\[\hat{e_i}=z_i-H_i\hat{X}\]</span> 则n次测量的误差（残差）平方和为优化指标： <span class="math display">\[J(\hat{X})=\sum_{i=1}^{n}{(z_i-H_i\hat{X})^2}=(Z-H\hat{X})^T(Z-H\hat{X}) \\=tr[(Z-H\hat{X})(Z-H\hat{X})^T]\]</span> 令<span class="math inline">\(\frac{\partial{J}}{\partial{\hat{X}}}=0\)</span> ,可得最小二乘估计值： <span class="math display">\[\hat{X}_{LS}=(H^TH)^{-1}H^TZ\]</span> 将<span class="math inline">\(Z=HX+V\)</span>此时状态的估计误差： <span class="math display">\[\tilde{X}_{LS}=X-\hat{X}_{LS}=-(H^TH)^{-1}H^TV\]</span> 若测量噪声均值为0，则<span class="math inline">\(E(\tilde{X}_{LS})=0\)</span>,此时最小二乘估计为<strong><u>无偏估计</u></strong>，<strong>状态估计误差的（协）方差[^ 2] <span class="math inline">\(Var(\tilde{X}_{LS})=E[(\tilde{X}-E\tilde{X})(\tilde{X}-E\tilde{X})^T]\)</span>与估计量的均方误差矩阵<span class="math inline">\(E[X-\hat{X}][X-\hat{X}]^T\)</span>相等</strong>。可见标准最小二乘不需要噪声V的任何统计信息。</p><p>由(5)式可得： <span class="math display">\[\begin{align}Var(\tilde{X}_{LS})=E[X-\hat{X}][X-\hat{X}]^T &amp; = (H^TH)^{-1}H^TE(VV^T)H(H^TH)^{-1}\\&amp;=(H^TH)^{-1}H^TRH(H^TH)^{-1}\end{align}\]</span> 其中<span class="math inline">\(R=E(VV^T)\)</span>为测量误差（噪声）的（协）方差阵。</p><h4 id="加权最小二乘weighted-least-square">加权最小二乘（weighted least square）</h4><p>在经典最小二乘中，假定每一次测量的权重相同，但是一般来说近期数据比远期数据影响更大，因此引入加权最小二乘，其指标形式： <span class="math display">\[J_W(\hat{X})=\sum_{i=1}^{n}{(z_i-H_i\hat{X})^2}=(Z-H\hat{X})^TW(Z-H\hat{X})\]</span> 同样使其偏导数为0,可得 <span class="math display">\[\hat{X}_{LSW}=(H^TWH)^{-1}H^TWZ\]</span></p><hr /><p>由附录<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>,若噪声不满足同方差，则普通最小二乘(4)并不是BLUE，此时噪声的协方差阵</p><p><span class="math inline">\(E[VV^T]=\sigma^2R,R\neq{I}\)</span> ,<span class="math inline">\(R=\begin{bmatrix}r_1\\&amp;\ddots\\&amp;&amp; r_n\end{bmatrix}\)</span>,即原模型存在异方差性。</p><p>设<span class="math inline">\(R=DD^T,D=\begin{bmatrix}\sqrt{r_1}\\&amp;\ddots\\&amp;&amp; \sqrt{r_n}\end{bmatrix}\)</span> ,用<span class="math inline">\(D^{-1}\)</span>同时左乘<span class="math inline">\(Z=HX+V\)</span>两端得到新的模型： <span class="math display">\[\begin{align}D^{-1}Z&amp;=D^{-1}HX+D^{-1}V \\Z^{\star}&amp;=H^{\star}X+V^{\star}\end{align}\]</span> 此时,原模型的加权最小二乘估计量为无偏的。 <span class="math display">\[\begin{align}E[V^{\star}V^{\star T}]&amp;=E[D^{-1}VV^TD^{-1\ T}]\\&amp;=D^{-1}E[VV^T]D^{-1\ T}\\&amp;=\sigma^2D^{-1}RD^{-1\ T}\\&amp;=\sigma^2I\end{align}\]</span> 此时得到的参数估计为： <span class="math display">\[\begin{align}\hat{X}_{LSW}&amp;=(H^{\star T}H^{\star})^{-1}H^{\star T}Z^{\star}\\&amp;=(H^TR^{-1}H)^{-1}H^TR^{-1}Z\end{align}\]</span> 可以证明（见附录），当<span class="math inline">\(W=R^{-1}\)</span>时，最小二乘估计时缺少初值条件下的<strong><u>线性无偏最小方差估计</u></strong>（BLUE,Best Linear Unbiased Estimation）——即能够使估计误差的方差阵最小，又称马尔可夫估计,其中 <span class="math display">\[R=E[VV^T]\]</span> 为随机噪声的（协）方差阵（对称正定阵）。</p><h4 id="递推最小二乘recursive-least-squarerls">递推最小二乘（Recursive Least Square,RLS）</h4><p>上述方法进行一次估计需要所有历史数据，不利于在线估计，考虑前n次测量： <span class="math display">\[Z_n=H_nX+V_n\]</span> 则加权的最小二乘估计为： <span class="math display">\[\hat{X}_{LSW}(n)=(H_{n}^TR_{n}^{-1}H_n)^{-1}H_{n}^TR_{n}^{-1}Z_n\]</span> 估计误差的（协）方差矩阵为： <span class="math display">\[\begin{align}P_n&amp;=E[\tilde{X}_{LSW}(n)\tilde{X}_{LSW}^T(n)]\\&amp;=E[-(H^TR^{-1}H)^{-1}]H^TR^{-1}VV^TR^{-1}H(H^TR^{-1}H)^{-1}\\&amp;=(H^TR^{-1}H)^{-1}H^TR^{-1}H(H^TR^{-1}H)^{-1}\\&amp;=(H^TR^{-1}H)^{-1}\end{align}\]</span> 结合上述两式，可得： <span class="math display">\[\hat{X}_{LSW}(n)=P_nH_{n}^TR_{n}^{-1}Z_n\]</span> 现得到一个新的测量值： <span class="math display">\[z_{n+1}=H_{n+1}X+v_{n+1}\]</span> 添加到矩阵中： <span class="math display">\[\hat{X}_{LSW}(n+1)=(H_{n+1}^TR_{n+1}^{-1}H_{n+1})^{-1}H_{n+1}^TR_{n+1}^{-1}Z_{n+1}\]</span> 将<u>新的测量噪声</u>加入到原本的测量噪声矩阵中：R阵应为对角阵： <span class="math display">\[R_{k+1}^{-1}=\begin{bmatrix}R_n^{-1} &amp; 0 \\0&amp;r^{-1}_{n+1}\end{bmatrix}\]</span> 将式子展开： <span class="math display">\[P_{n+1}^{-1}=H_{n+1}^TR_{n+1}^{-1}H_{n+1}=[H_n^T,h_{n+1}^T]\begin{bmatrix}R_n^{-1} &amp; 0 \\0&amp;r^{-1}_{n+1}\end{bmatrix}\begin{bmatrix}H_n\\h_{n+1}\end{bmatrix}=H_n^TR_n^{-1}H_n+h_{n+1}^Tr_{n+1}^{-1}h_{n+1}\]</span> 即： <span class="math display">\[P_{n+1}^{-1}=P_n^{-1}+h_{n+1}^Tr_{n+1}^{-1}h_{n+1}\]</span> 综上，可以推得： <span class="math display">\[\begin{align}P_{n+1}&amp;=P_n-P_nh_{n+1}^T[h_{n+1}P_nh_{n+1}^T+r_{n+1}]^{-1}h_{n+1}P_n\\K_{n+1} &amp;= P_{n+1}h_{n+1}^Tr_{n+1}^{-1}\\\hat{X}_{LSW}(n+1)&amp;=\hat{X}_{LSW}(n)+K_{n+1}[z_{n+1}-h_{n+1}\hat{X}_{LSW}(n)]\end{align}\]</span> 其中<span class="math inline">\(K_{n+1}\)</span>可将(31)代入展开为： <span class="math display">\[K_{n+1} = P_nh_{n+1}^T[h_{n+1}P_nh_{n+1}^T+r_{n+1}]^{-1}\]</span> 因此<span class="math inline">\(P_{n+1}\)</span>亦可表示为： <span class="math display">\[P_{n+1}=P_n-K_{n+1}h_{n+1}P_n\]</span></p><h4 id="卡尔曼滤波">卡尔曼滤波</h4><p>若被估计量X不随时间变化，或随时间缓慢变化则为“静态估计”，而被估计量随时间变化为“动态估计”。</p><p>参考：</p><blockquote><p>https://blog.csdn.net/qinruiyan/article/details/50793114</p><p>《最优估计理论》刘胜，张红梅，科学出版社</p><h6 id="最佳线性无偏估计gm假设">最佳线性无偏估计（GM假设）</h6><p>假设多元线性回归模型：<span class="math inline">\(Z=HX+V\)</span> <span class="math display">\[\begin{align}Z&amp;=(z_1,\dots,z_n)^T\\H&amp;=\begin{bmatrix}h_{ij}\end{bmatrix}_{n\times{p}}\\X&amp;=(x_o,\dots,x_p)\\V&amp;=(v_0,\dots,v_n)\end{align}\]</span> 则GM假设： <span class="math display">\[\begin{align}E(V|H)&amp;=0,\forall H\ (零均值)\\Var(V|H)&amp;=E(VV^T|H)=\sigma^2I_n\ (同方差且不相关)\end{align}\]</span> 则此时对参数X的最佳线性无偏估计为： <span class="math display">\[\hat{X}=(H^TH)^{-1}H^TZ\]</span></p><h6 id="最小二乘估计与最小方差估计等价条件证明">最小二乘估计与最小方差估计等价条件证明：</h6><figure><img src="C:\Users\Jachin%20Jac\AppData\Roaming\Typora\typora-user-images\image-20191216221314847.png" alt="image-20191216221314847" /><figcaption>image-20191216221314847</figcaption></figure><h6 id="各种估计方法的比较">各种估计方法的比较：</h6><figure><img src="C:\Users\Jachin%20Jac\AppData\Roaming\Typora\typora-user-images\image-20191216221240802.png" alt="image-20191216221240802" /><figcaption>image-20191216221240802</figcaption></figure></blockquote><section class="footnotes"><hr /><ol><li id="fn1"><p>残差在数理统计中是指实际观察值和估计值之间的差。若设线性回归模型为<span class="math inline">\(Z=HX+V\)</span> ,其中Z为n维输出向量，H是<span class="math inline">\(n\times(p+1)\)</span> 阶设计矩阵，X是p+1维向量，V为n维随机变量(扰动)。则回归系数的估计值<span class="math inline">\(\hat{X}=(H^TH)^{-1}H^TZ\)</span> ，拟合值<span class="math inline">\(\hat{Z} = H\hat{X}=H(H^TH)^{-1}H^TZ\)</span>,残差为<span class="math inline">\(\hat{\epsilon}=z_i-\hat{z_i}=z_i-H_i\hat{X}\)</span> ，其由观测真值和H阵给出，不考虑噪声V。 [^ 2]: https://zh.wikipedia.org/wiki/%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5<img src="C:\Users\Jachin Jac\AppData\Roaming\Typora\typora-user-images\image-20191215194027795.png" alt="image-20191215194027795" style="zoom:50%;" /><a href="#fnref1" class="footnote-back">↩</a></p></li><li id="fn2"><p>在线性回归模型中，如果随机噪声（误差）满足<strong>零均值、同方差且互不相关</strong>，则回归系数的最优线性无偏估计（BLUE，Best Linear unbiased estimator）就是普通最小二乘估计。<a href="#fnref2" class="footnote-back">↩</a></p></li></ol></section>]]></content>
      
      
      <categories>
          
          <category> 最优估计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>a</title>
      <link href="/2020/02/03/a/"/>
      <url>/2020/02/03/a/</url>
      
        <content type="html"><![CDATA[<p><code>aaaa</code></p><ul><li>a</li></ul><p><span class="math display">\[ a_1 \]</span></p><p><span class="math inline">\(a^1\)</span></p><p><span class="math display">\[\begin{align}x &amp;= a +b+c+d\\ &amp;= e +f\\ &amp;= g\end{align}\]</span></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/02/03/hello-world/"/>
      <url>/2020/02/03/hello-world/</url>
      
        <content type="html"><![CDATA[<p>正式博客的破壳日 o(￣ヘ￣o#) <a id="more"></a> More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>apollo感知模块.md</title>
      <link href="/2020/01/28/apollo%E6%84%9F%E7%9F%A5/"/>
      <url>/2020/01/28/apollo%E6%84%9F%E7%9F%A5/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 无人驾驶 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 感知 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
